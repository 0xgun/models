{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          2  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"dataset/train.tsv\", sep=\"\\t\")\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156060, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>This quiet , introspective and entertaining in...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>82</td>\n",
       "      <td>3</td>\n",
       "      <td>Even fans of Ismail Merchant 's work , I suspe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>117</td>\n",
       "      <td>4</td>\n",
       "      <td>A positively thrilling combination of ethnogra...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>157</td>\n",
       "      <td>5</td>\n",
       "      <td>Aggressive self-glorification and a manipulati...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PhraseId  SentenceId                                             Phrase  \\\n",
       "0           1           1  A series of escapades demonstrating the adage ...   \n",
       "63         64           2  This quiet , introspective and entertaining in...   \n",
       "81         82           3  Even fans of Ismail Merchant 's work , I suspe...   \n",
       "116       117           4  A positively thrilling combination of ethnogra...   \n",
       "156       157           5  Aggressive self-glorification and a manipulati...   \n",
       "\n",
       "     Sentiment  \n",
       "0            1  \n",
       "63           4  \n",
       "81           1  \n",
       "116          3  \n",
       "156          1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.drop_duplicates(subset=\"SentenceId\", keep=\"first\", inplace=True)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8529, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8529 entries, 0 to 156039\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   PhraseId    8529 non-null   int64 \n",
      " 1   SentenceId  8529 non-null   int64 \n",
      " 2   Phrase      8529 non-null   object\n",
      " 3   Sentiment   8529 non-null   int64 \n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 333.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    2321\n",
       "1    2200\n",
       "2    1655\n",
       "4    1281\n",
       "0    1072\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[\"Sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 10000x2500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.displot(df1[\"Phrase\"].apply(lambda x: len(x.split())))\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.figure(figsize=(100,25))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ganes\\anaconda3\\envs\\project\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading (…)okenizer_config.json: 100%|██████████████████████████████████████████| 29.0/29.0 [00:00<00:00, 7.27kB/s]\n",
      "C:\\Users\\ganes\\anaconda3\\envs\\project\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ganes\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Downloading (…)lve/main/config.json: 100%|█████████████████████████████████████████████| 570/570 [00:00<00:00, 104kB/s]\n",
      "Downloading (…)solve/main/vocab.txt: 100%|███████████████████████████████████████████| 213k/213k [00:00<00:00, 527kB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|███████████████████████████████████████████| 436k/436k [00:00<00:00, 733kB/s]\n"
     ]
    }
   ],
   "source": [
    "SEQ_LEN = 50\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8529, 50), (8529, 50))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xids = np.zeros((len(df1), SEQ_LEN))\n",
    "Xmask = np.zeros((len(df1), SEQ_LEN))\n",
    "\n",
    "Xids.shape, Xmask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sequence in enumerate(df1[\"Phrase\"]):\n",
    "    tokens = tokenizer.encode_plus(sequence, max_length=SEQ_LEN, \n",
    "                               truncation=True, padding=\"max_length\",\n",
    "                               add_special_tokens=True, return_token_type_ids=False,\n",
    "                               return_attention_mask=True, return_tensors=\"tf\"\n",
    "                              )\n",
    "    Xids[i, :], Xmask[i, :] = tokens[\"input_ids\"], tokens[\"attention_mask\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbl_arr = df1[\"Sentiment\"].values\n",
    "final_labels = np.zeros((lbl_arr.size, lbl_arr.max()+1))\n",
    "\n",
    "final_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_labels[np.arange(lbl_arr.size), lbl_arr] = 1\n",
    "final_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dataset/bertDataset.npz\", \"wb\") as f:\n",
    "    np.savez(f, Xids = Xids, Xmask = Xmask, labels = final_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "del Xids, Xmask, final_labels, df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dataset/bertDataset.npz\", \"rb\") as f:\n",
    "    data = np.load(f)\n",
    "    \n",
    "    Xids = data[\"Xids\"]\n",
    "    Xmask = data[\"Xmask\"]\n",
    "    labels = data[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8529, 50), (8529, 50), (8529, 5))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xids.shape, Xmask.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((Xids, Xmask, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_func(input_ids, masks, labels):\n",
    "    return {\"input_ids\": input_ids, \"attention_mask\": masks}, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'input_ids': <tf.Tensor: shape=(50,), dtype=float64, numpy=\n",
      "array([  101.,   138.,  1326.,  1104., 13936., 25265., 16913., 15107.,\n",
      "        1103.,  8050.,  2553.,  1115.,  1184.,  1110.,  1363.,  1111.,\n",
      "        1103., 20398.,  1110.,  1145.,  1363.,  1111.,  1103.,   176.,\n",
      "        9900.,   117.,  1199.,  1104.,  1134.,  5411.,  1821., 14225.,\n",
      "        1133.,  3839.,  1104.,  1134.,  7919.,  1106.,  1277.,  1104.,\n",
      "         170.,  1642.,   119.,   102.,     0.,     0.,     0.,     0.,\n",
      "           0.,     0.])>, 'attention_mask': <tf.Tensor: shape=(50,), dtype=float64, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.])>}, <tf.Tensor: shape=(5,), dtype=float64, numpy=array([0., 1., 0., 0., 0.])>)\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.map(map_func)\n",
    "\n",
    "for i in dataset.take(1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.shuffle(1000000).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS_LEN = len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT = 0.9\n",
    "\n",
    "train_data = dataset.take(round(DS_LEN * SPLIT))\n",
    "val_data = dataset.skip(round(DS_LEN * SPLIT))\n",
    "\n",
    "del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading tf_model.h5: 100%|██████████████████████████████████████████████████████| 527M/527M [00:39<00:00, 13.5MB/s]\n",
      "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFAutoModel\n",
    "\n",
    "bert = TFAutoModel.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tf.keras.layers.Input(shape=(SEQ_LEN, ), name=\"input_ids\", dtype=\"int32\")\n",
    "mask = tf.keras.layers.Input(shape=(SEQ_LEN, ), name=\"attention_mask\", dtype=\"int32\")\n",
    "\n",
    "embeddings = bert(input_ids, attention_mask=mask)[0]\n",
    "\n",
    "X = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
    "X = tf.keras.layers.BatchNormalization()(X)\n",
    "X = tf.keras.layers.Dense(64, activation=\"relu\")(X)\n",
    "X = tf.keras.layers.Dense(128, activation=\"relu\")(X)\n",
    "X = tf.keras.layers.Dropout(0.1)(X)\n",
    "X = tf.keras.layers.Dense(64, activation=\"relu\")(X)\n",
    "X = tf.keras.layers.Dense(32, activation=\"relu\")(X)\n",
    "\n",
    "y = tf.keras.layers.Dense(5, activation=\"softmax\",  name=\"outputs\")(X)\n",
    "\n",
    "model = tf.keras.Model(inputs=[input_ids, mask], outputs=y)\n",
    "\n",
    "model.layers[2].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "attention_mask (InputLayer)     [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_bert_model (TFBertModel)     TFBaseModelOutputWit 108310272   input_ids[0][0]                  \n",
      "                                                                 attention_mask[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d (GlobalMax (None, 768)          0           tf_bert_model[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 768)          3072        global_max_pooling1d[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 64)           49216       batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          8320        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 128)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64)           8256        dropout_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 32)           2080        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, 5)            165         dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 108,381,381\n",
      "Trainable params: 69,573\n",
      "Non-trainable params: 108,311,808\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\",patience=8),\n",
    "            tf.keras.callbacks.ModelCheckpoint(\"bert_model.h5\",verbose= 1 ,save_best_only=True)]\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(0.001)\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "acc = tf.keras.metrics.CategoricalAccuracy(\"accuracy\")\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "240/240 [==============================] - ETA: 0s - loss: 1.4444 - accuracy: 0.3569\n",
      "Epoch 00001: val_loss improved from inf to 1.29720, saving model to bert_model.h5\n",
      "240/240 [==============================] - 660s 3s/step - loss: 1.4444 - accuracy: 0.3569 - val_loss: 1.2972 - val_accuracy: 0.4264\n",
      "Epoch 2/200\n",
      "240/240 [==============================] - ETA: 0s - loss: 1.3075 - accuracy: 0.4294\n",
      "Epoch 00002: val_loss improved from 1.29720 to 1.22915, saving model to bert_model.h5\n",
      "240/240 [==============================] - 678s 3s/step - loss: 1.3075 - accuracy: 0.4294 - val_loss: 1.2292 - val_accuracy: 0.4888\n",
      "Epoch 3/200\n",
      "240/240 [==============================] - ETA: 0s - loss: 1.2798 - accuracy: 0.4495\n",
      "Epoch 00003: val_loss improved from 1.22915 to 1.16856, saving model to bert_model.h5\n",
      "240/240 [==============================] - 681s 3s/step - loss: 1.2798 - accuracy: 0.4495 - val_loss: 1.1686 - val_accuracy: 0.4865\n",
      "Epoch 4/200\n",
      "240/240 [==============================] - ETA: 0s - loss: 1.2370 - accuracy: 0.4612\n",
      "Epoch 00004: val_loss improved from 1.16856 to 1.13590, saving model to bert_model.h5\n",
      "240/240 [==============================] - 901s 4s/step - loss: 1.2370 - accuracy: 0.4612 - val_loss: 1.1359 - val_accuracy: 0.5171\n",
      "Epoch 5/200\n",
      "240/240 [==============================] - ETA: 0s - loss: 1.2276 - accuracy: 0.4714\n",
      "Epoch 00005: val_loss improved from 1.13590 to 1.10399, saving model to bert_model.h5\n",
      "240/240 [==============================] - 847s 4s/step - loss: 1.2276 - accuracy: 0.4714 - val_loss: 1.1040 - val_accuracy: 0.5489\n",
      "Epoch 6/200\n",
      "240/240 [==============================] - ETA: 0s - loss: 1.2078 - accuracy: 0.4784\n",
      "Epoch 00006: val_loss improved from 1.10399 to 1.05034, saving model to bert_model.h5\n",
      "240/240 [==============================] - 853s 4s/step - loss: 1.2078 - accuracy: 0.4784 - val_loss: 1.0503 - val_accuracy: 0.5795\n",
      "Epoch 7/200\n",
      "240/240 [==============================] - ETA: 0s - loss: 1.1871 - accuracy: 0.4874\n",
      "Epoch 00007: val_loss improved from 1.05034 to 1.04555, saving model to bert_model.h5\n",
      "240/240 [==============================] - 862s 4s/step - loss: 1.1871 - accuracy: 0.4874 - val_loss: 1.0455 - val_accuracy: 0.5595\n",
      "Epoch 8/200\n",
      "240/240 [==============================] - ETA: 0s - loss: 1.1748 - accuracy: 0.4944\n",
      "Epoch 00008: val_loss did not improve from 1.04555\n",
      "240/240 [==============================] - 586s 2s/step - loss: 1.1748 - accuracy: 0.4944 - val_loss: 1.0494 - val_accuracy: 0.5336\n",
      "Epoch 9/200\n",
      "240/240 [==============================] - ETA: 0s - loss: 1.1569 - accuracy: 0.5079\n",
      "Epoch 00009: val_loss improved from 1.04555 to 0.99863, saving model to bert_model.h5\n",
      "240/240 [==============================] - 548s 2s/step - loss: 1.1569 - accuracy: 0.5079 - val_loss: 0.9986 - val_accuracy: 0.5984\n",
      "Epoch 10/200\n",
      "240/240 [==============================] - ETA: 0s - loss: 1.1415 - accuracy: 0.5083\n",
      "Epoch 00010: val_loss improved from 0.99863 to 0.97923, saving model to bert_model.h5\n",
      "240/240 [==============================] - 570s 2s/step - loss: 1.1415 - accuracy: 0.5083 - val_loss: 0.9792 - val_accuracy: 0.5995\n",
      "Epoch 11/200\n",
      "240/240 [==============================] - ETA: 0s - loss: 1.1263 - accuracy: 0.5207\n",
      "Epoch 00011: val_loss improved from 0.97923 to 0.95937, saving model to bert_model.h5\n",
      "240/240 [==============================] - 605s 3s/step - loss: 1.1263 - accuracy: 0.5207 - val_loss: 0.9594 - val_accuracy: 0.6019\n",
      "Epoch 12/200\n",
      "240/240 [==============================] - ETA: 0s - loss: 1.1082 - accuracy: 0.5270\n",
      "Epoch 00012: val_loss improved from 0.95937 to 0.88352, saving model to bert_model.h5\n",
      "240/240 [==============================] - 529s 2s/step - loss: 1.1082 - accuracy: 0.5270 - val_loss: 0.8835 - val_accuracy: 0.6584\n",
      "Epoch 13/200\n",
      "240/240 [==============================] - ETA: 0s - loss: 1.0930 - accuracy: 0.5374\n",
      "Epoch 00013: val_loss improved from 0.88352 to 0.85590, saving model to bert_model.h5\n",
      "240/240 [==============================] - 531s 2s/step - loss: 1.0930 - accuracy: 0.5374 - val_loss: 0.8559 - val_accuracy: 0.6549\n",
      "Epoch 14/200\n",
      "240/240 [==============================] - ETA: 0s - loss: 1.0733 - accuracy: 0.5404\n",
      "Epoch 00014: val_loss improved from 0.85590 to 0.82286, saving model to bert_model.h5\n",
      "240/240 [==============================] - 524s 2s/step - loss: 1.0733 - accuracy: 0.5404 - val_loss: 0.8229 - val_accuracy: 0.6726\n",
      "Epoch 15/200\n",
      "240/240 [==============================] - ETA: 0s - loss: 1.0671 - accuracy: 0.5466\n",
      "Epoch 00015: val_loss improved from 0.82286 to 0.81007, saving model to bert_model.h5\n",
      "240/240 [==============================] - 517s 2s/step - loss: 1.0671 - accuracy: 0.5466 - val_loss: 0.8101 - val_accuracy: 0.6949\n",
      "Epoch 16/200\n",
      "240/240 [==============================] - ETA: 0s - loss: 1.0413 - accuracy: 0.5637\n",
      "Epoch 00016: val_loss did not improve from 0.81007\n",
      "240/240 [==============================] - 513s 2s/step - loss: 1.0413 - accuracy: 0.5637 - val_loss: 0.8204 - val_accuracy: 0.6879\n",
      "Epoch 17/200\n",
      "240/240 [==============================] - ETA: 0s - loss: 1.0405 - accuracy: 0.5639\n",
      "Epoch 00017: val_loss improved from 0.81007 to 0.79696, saving model to bert_model.h5\n",
      "240/240 [==============================] - 513s 2s/step - loss: 1.0405 - accuracy: 0.5639 - val_loss: 0.7970 - val_accuracy: 0.6867\n",
      "Epoch 18/200\n",
      "240/240 [==============================] - ETA: 0s - loss: 1.0271 - accuracy: 0.5669\n",
      "Epoch 00018: val_loss improved from 0.79696 to 0.76091, saving model to bert_model.h5\n",
      "240/240 [==============================] - 555s 2s/step - loss: 1.0271 - accuracy: 0.5669 - val_loss: 0.7609 - val_accuracy: 0.7267\n",
      "Epoch 19/200\n",
      "240/240 [==============================] - ETA: 0s - loss: 1.0216 - accuracy: 0.5737\n",
      "Epoch 00019: val_loss improved from 0.76091 to 0.75388, saving model to bert_model.h5\n",
      "240/240 [==============================] - 583s 2s/step - loss: 1.0216 - accuracy: 0.5737 - val_loss: 0.7539 - val_accuracy: 0.7197\n",
      "Epoch 20/200\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.9919 - accuracy: 0.5858\n",
      "Epoch 00020: val_loss improved from 0.75388 to 0.68483, saving model to bert_model.h5\n",
      "240/240 [==============================] - 575s 2s/step - loss: 0.9919 - accuracy: 0.5858 - val_loss: 0.6848 - val_accuracy: 0.7621\n",
      "Epoch 21/200\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.9837 - accuracy: 0.5861\n",
      "Epoch 00021: val_loss improved from 0.68483 to 0.66927, saving model to bert_model.h5\n",
      "240/240 [==============================] - 570s 2s/step - loss: 0.9837 - accuracy: 0.5861 - val_loss: 0.6693 - val_accuracy: 0.7491\n",
      "Epoch 22/200\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.9792 - accuracy: 0.5857\n",
      "Epoch 00022: val_loss did not improve from 0.66927\n",
      "240/240 [==============================] - 555s 2s/step - loss: 0.9792 - accuracy: 0.5857 - val_loss: 0.6995 - val_accuracy: 0.7303\n",
      "Epoch 23/200\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.9729 - accuracy: 0.5918\n",
      "Epoch 00023: val_loss did not improve from 0.66927\n",
      "240/240 [==============================] - 553s 2s/step - loss: 0.9729 - accuracy: 0.5918 - val_loss: 0.6914 - val_accuracy: 0.7326\n",
      "Epoch 24/200\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.9618 - accuracy: 0.6025\n",
      "Epoch 00024: val_loss improved from 0.66927 to 0.63414, saving model to bert_model.h5\n",
      "240/240 [==============================] - 575s 2s/step - loss: 0.9618 - accuracy: 0.6025 - val_loss: 0.6341 - val_accuracy: 0.7656\n",
      "Epoch 25/200\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.9505 - accuracy: 0.6120\n",
      "Epoch 00025: val_loss did not improve from 0.63414\n",
      "240/240 [==============================] - 623s 3s/step - loss: 0.9505 - accuracy: 0.6120 - val_loss: 0.6545 - val_accuracy: 0.7609\n",
      "Epoch 26/200\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.9428 - accuracy: 0.6107\n",
      "Epoch 00026: val_loss improved from 0.63414 to 0.60010, saving model to bert_model.h5\n",
      "240/240 [==============================] - 577s 2s/step - loss: 0.9428 - accuracy: 0.6107 - val_loss: 0.6001 - val_accuracy: 0.7939\n",
      "Epoch 27/200\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.9249 - accuracy: 0.6180\n",
      "Epoch 00027: val_loss did not improve from 0.60010\n",
      "240/240 [==============================] - 604s 3s/step - loss: 0.9249 - accuracy: 0.6180 - val_loss: 0.6055 - val_accuracy: 0.7927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/200\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.9202 - accuracy: 0.6191\n",
      "Epoch 00028: val_loss improved from 0.60010 to 0.56571, saving model to bert_model.h5\n",
      "240/240 [==============================] - 593s 2s/step - loss: 0.9202 - accuracy: 0.6191 - val_loss: 0.5657 - val_accuracy: 0.8139\n",
      "Epoch 29/200\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.9010 - accuracy: 0.6314\n",
      "Epoch 00029: val_loss improved from 0.56571 to 0.55613, saving model to bert_model.h5\n",
      "240/240 [==============================] - 670s 3s/step - loss: 0.9010 - accuracy: 0.6314 - val_loss: 0.5561 - val_accuracy: 0.8068\n",
      "Epoch 30/200\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.9018 - accuracy: 0.6280\n",
      "Epoch 00030: val_loss improved from 0.55613 to 0.52732, saving model to bert_model.h5\n",
      "240/240 [==============================] - 585s 2s/step - loss: 0.9018 - accuracy: 0.6280 - val_loss: 0.5273 - val_accuracy: 0.8245\n",
      "Epoch 31/200\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.9011 - accuracy: 0.6311\n",
      "Epoch 00031: val_loss did not improve from 0.52732\n",
      "240/240 [==============================] - 639s 3s/step - loss: 0.9011 - accuracy: 0.6311 - val_loss: 0.5449 - val_accuracy: 0.8115\n",
      "Epoch 32/200\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.8745 - accuracy: 0.6449\n",
      "Epoch 00032: val_loss improved from 0.52732 to 0.48737, saving model to bert_model.h5\n",
      "240/240 [==============================] - 611s 3s/step - loss: 0.8745 - accuracy: 0.6449 - val_loss: 0.4874 - val_accuracy: 0.8469\n",
      "Epoch 33/200\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.8692 - accuracy: 0.6409\n",
      "Epoch 00033: val_loss did not improve from 0.48737\n",
      "240/240 [==============================] - 598s 2s/step - loss: 0.8692 - accuracy: 0.6409 - val_loss: 0.5073 - val_accuracy: 0.8104\n",
      "Epoch 34/200\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.8686 - accuracy: 0.6491\n",
      "Epoch 00034: val_loss did not improve from 0.48737\n",
      "240/240 [==============================] - 513s 2s/step - loss: 0.8686 - accuracy: 0.6491 - val_loss: 0.5450 - val_accuracy: 0.8057\n",
      "Epoch 35/200\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.8685 - accuracy: 0.6483\n",
      "Epoch 00035: val_loss did not improve from 0.48737\n",
      "240/240 [==============================] - 481s 2s/step - loss: 0.8685 - accuracy: 0.6483 - val_loss: 0.4934 - val_accuracy: 0.8516\n",
      "Epoch 36/200\n",
      "206/240 [========================>.....] - ETA: 1:02 - loss: 0.8635 - accuracy: 0.6482"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data, \n",
    "                   validation_data=val_data,\n",
    "                   epochs=200,\n",
    "                   callbacks=callbacks\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = history\n",
    "plt.figure(figsize=(15,6))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(hist.epoch,hist.history['accuracy'],label = 'Training')\n",
    "plt.plot(hist.epoch,hist.history['val_accuracy'],label = 'validation')\n",
    "\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(hist.epoch,hist.history['loss'],label = 'Training')\n",
    "plt.plot(hist.epoch,hist.history['val_loss'],label = 'validation')\n",
    "\n",
    "plt.title(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_input(sen:str, seq_len:int):\n",
    "    tokens = tokenizer.encode_plus(sen, max_length=seq_len, \n",
    "                               truncation=True, padding=\"max_length\",\n",
    "                               add_special_tokens=True, return_token_type_ids=False,\n",
    "                               return_attention_mask=True, return_tensors=\"tf\"\n",
    "                              )\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFBertModel\n",
    "\n",
    "# Define the custom objects dictionary with the TFBertModel layer\n",
    "custom_objects = {'TFBertModel': TFBertModel}\n",
    "\n",
    "# Load the model and pass the custom objects dictionary\n",
    "model = tf.keras.models.load_model('bert_model.h5', custom_objects=custom_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {\n",
    "    0: \"Negative\",\n",
    "    1: \"Somewhat Negative\",\n",
    "    2: \"Neutral\",\n",
    "    3: \"Somewhat Positive\",\n",
    "    4: \"Positive\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"dataset/test.tsv\", sep=\"\\t\")\n",
    "df2.drop_duplicates(subset=\"SentenceId\", keep=\"first\", inplace=True)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_out = {}\n",
    "\n",
    "for i in tqdm(range(100)):\n",
    "    to_test = df2[\"Phrase\"].iloc[i]\n",
    "#     print(to_test)\n",
    "\n",
    "    test_input = map_to_input(to_test, SEQ_LEN)\n",
    "    input_ids = test_input[\"input_ids\"]\n",
    "    mask = test_input[\"attention_mask\"]\n",
    "    \n",
    "    pred = model.predict([input_ids, mask], verbose=0)\n",
    "#     print(f\"The output class is: {classes[np.argmax(pred[0])]}\")\n",
    "    final_out[to_test] = classes[np.argmax(pred[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in final_out.keys():\n",
    "    print(f\"{i[:100]} ==> {final_out[i]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
